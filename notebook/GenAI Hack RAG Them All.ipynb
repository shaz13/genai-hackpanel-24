{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02e9b0a-07ff-4cf3-b4bb-0d8b0793288b",
   "metadata": {},
   "source": [
    "## RAG Them All!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b2789-1739-4dd3-bb82-9bb1c7ddd3f6",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f383ba-ff6b-4da3-8dce-c68a7e4016d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import faiss\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer, StorageContext\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "from llama_index.core import Settings\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval import TruLlama\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval.feedback import GroundTruthAgreement\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval.app import App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb8f71-c35b-42ff-80a4-b23b3a1557f1",
   "metadata": {},
   "source": [
    "### Configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4e5704-f499-4854-be04-3577c0686fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_TOKEN  # Set OpenAI Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "151f011a-d1ec-43b9-8dea-2748d1bd9218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Test Data\n",
    "test_data = pd.read_csv(\"../data/financial-qa-dataset/financial_qna_with_metadata.csv\")\n",
    "alphabet_10k_question_df = (\n",
    "    test_data[(test_data[\"Entity\"] == \"Alphabet\") & (test_data[\"Year\"] == 2023)]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b74bb9-8129-4dea-9976-4f2a9b1356d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Contexts</th>\n",
       "      <th>Document</th>\n",
       "      <th>Page_no</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Document_type</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the value of Alphabet's total current...</td>\n",
       "      <td>$171,530 million</td>\n",
       "      <td>Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...</td>\n",
       "      <td>goog-10-k-2023.pdf</td>\n",
       "      <td>page_0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Alphabet</td>\n",
       "      <td>annual report</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the total value of Alphabet's  market...</td>\n",
       "      <td>$86,868 million</td>\n",
       "      <td>Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...</td>\n",
       "      <td>goog-10-k-2023.pdf</td>\n",
       "      <td>page_0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Alphabet</td>\n",
       "      <td>annual report</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the value of Alphabet's goodwill in 2...</td>\n",
       "      <td>$28,960 million</td>\n",
       "      <td>Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...</td>\n",
       "      <td>goog-10-k-2023.pdf</td>\n",
       "      <td>page_0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Alphabet</td>\n",
       "      <td>annual report</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What amount of long-term debt did Alphabet hav...</td>\n",
       "      <td>$13,253 million</td>\n",
       "      <td>Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...</td>\n",
       "      <td>goog-10-k-2023.pdf</td>\n",
       "      <td>page_0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Alphabet</td>\n",
       "      <td>annual report</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the total value of Alphabet's accrued...</td>\n",
       "      <td>$37,866 million</td>\n",
       "      <td>Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...</td>\n",
       "      <td>goog-10-k-2023.pdf</td>\n",
       "      <td>page_0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Alphabet</td>\n",
       "      <td>annual report</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions           Answers  \\\n",
       "0  What was the value of Alphabet's total current...  $171,530 million   \n",
       "1  What was the total value of Alphabet's  market...   $86,868 million   \n",
       "2  What was the value of Alphabet's goodwill in 2...   $28,960 million   \n",
       "3  What amount of long-term debt did Alphabet hav...   $13,253 million   \n",
       "4  What was the total value of Alphabet's accrued...   $37,866 million   \n",
       "\n",
       "                                            Contexts            Document  \\\n",
       "0  Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...  goog-10-k-2023.pdf   \n",
       "1  Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...  goog-10-k-2023.pdf   \n",
       "2  Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...  goog-10-k-2023.pdf   \n",
       "3  Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...  goog-10-k-2023.pdf   \n",
       "4  Alphabet Inc.\\nCONSOLIDATED BALANCE SHEETS\\n(i...  goog-10-k-2023.pdf   \n",
       "\n",
       "  Page_no  Year      Sector    Entity  Document_type  Quarter  \n",
       "0  page_0  2023  Technology  Alphabet  annual report      NaN  \n",
       "1  page_0  2023  Technology  Alphabet  annual report      NaN  \n",
       "2  page_0  2023  Technology  Alphabet  annual report      NaN  \n",
       "3  page_0  2023  Technology  Alphabet  annual report      NaN  \n",
       "4  page_0  2023  Technology  Alphabet  annual report      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet_10k_question_df = (\n",
    "    test_data[(test_data[\"Entity\"] == \"Alphabet\") & (test_data[\"Year\"] == 2023)]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(alphabet_10k_question_df.shape[0])\n",
    "alphabet_10k_question_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702ca53a-5d95-44ae-b607-ea5c56eb7da7",
   "metadata": {},
   "source": [
    "### Experimentation Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3378fd49-d48e-4025-9e4a-721ad92e28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "exps = [\n",
    "    # [\"Exp#1: GPT-4o + ada002\",\n",
    "    #      OpenAI(model=\"gpt-4o\", temperature=0),\n",
    "    #      OpenAIEmbedding(model='text-embedding-ada-002')\n",
    "    # ],\n",
    "    [\n",
    "        \"Exp#2 GPT-4o-mini + ada002\",\n",
    "        OpenAI(model=\"gpt-4o-mini\"),\n",
    "        OpenAIEmbedding(model=\"text-embedding-ada-002\"),\n",
    "    ],\n",
    "    [\n",
    "        \"Exp#3: Llama 3.1 + ada002\",\n",
    "        Ollama(model=\"llama3.1:latest\", request_timeout=120.0),\n",
    "        OpenAIEmbedding(model=\"text-embedding-ada-002\"),\n",
    "    ],\n",
    "    # [\"Exp#4: Llama 3.1 + fin-invest\",\n",
    "    #      Ollama(model=\"llama3.1:latest\", request_timeout=120.0),\n",
    "    #      HuggingFaceEmbedding(model_name=\"FinLang/finance-embeddings-investopedia\")\n",
    "    # ],\n",
    "    [\n",
    "        \"Exp#5: Llama 3.1 + bge-large\",\n",
    "        Ollama(model=\"llama3.1:latest\", request_timeout=220.0),\n",
    "        HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\"),\n",
    "    ],\n",
    "    # [\"Exp#6: Gemma 2 + fin-invest\",\n",
    "    #      Ollama(model=\"gemma2\", request_timeout=120.0),\n",
    "    #      HuggingFaceEmbedding(model_name=\"FinLang/finance-embeddings-investopedia\")\n",
    "    # ],\n",
    "    # [\"Exp#7: Gemma 2 + bge-large\",\n",
    "    #      Ollama(model=\"gemma2\", request_timeout=120.0),\n",
    "    #      HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "    # ],\n",
    "    # [\"Exp#8: Gemma 2 + ada002\",\n",
    "    #      Ollama(model=\"gemma2\", request_timeout=120.0),\n",
    "    #      OpenAIEmbedding(model_name=\"text-embedding-ada-002\")\n",
    "    # ],\n",
    "    # [\"Exp#9: Mistral + ada002\",\n",
    "    #      Ollama(model=\"mistral\", request_timeout=120.0),\n",
    "    #      OpenAIEmbedding(model_name=\"text-embedding-ada-002\")\n",
    "    # ],\n",
    "]\n",
    "# pprint([x for x in exps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ad2973a-6495-4456-bb63-56e042230876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e8780-fd31-43fe-95b1-b69b66320391",
   "metadata": {},
   "source": [
    "### TruLens Db Init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090ded20-5634-44ac-9aa4-a31f4a6cd6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7897c376-763c-4fb6-8d66-efabe0cd9626",
   "metadata": {},
   "source": [
    "## Experiment Runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a0296b-fb08-4bf6-8c8a-a1708af351f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "       Running Exp#2 GPT-4o-mini + ada002        \n",
      "=================================================\n",
      ">> Loading index from local\n",
      "Index loaded\n",
      "✅ In Ground Truth, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Ground Truth, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [01:05<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "       Running Exp#3: Llama 3.1 + ada002        \n",
      "=================================================\n",
      ">> Loading index from local\n",
      "Index loaded\n",
      "✅ In Ground Truth, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Ground Truth, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [10:09<00:00, 20.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "       Running Exp#5: Llama 3.1 + bge-large        \n",
      "=================================================\n",
      ">> Loading index from local\n",
      "Index loaded\n",
      "✅ In Ground Truth, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Ground Truth, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [15:37<00:00, 31.25s/it]\n"
     ]
    }
   ],
   "source": [
    "qa_prompt_tmpl = \"\"\"You are a financial expert on 10k annual company reportings. Answer the following question. Answer 2-3 words only:\n",
    "\n",
    "    Question: {query_str}\\n\n",
    "    Context:\\n{context_str}\\n\n",
    "    Answer: \n",
    "\"\"\"\n",
    "qa_prompt = PromptTemplate(qa_prompt_tmpl)\n",
    "\n",
    "\n",
    "for exp_name, llm, emb_model in exps:\n",
    "    print(\"=================================================\")\n",
    "    print(f\"       Running {exp_name}        \")\n",
    "    print(\"=================================================\")\n",
    "\n",
    "    Settings.llm = llm\n",
    "    Settings.embed_model = emb_model\n",
    "\n",
    "    try:\n",
    "\n",
    "        if emb_model.model_name == \"text-embedding-ada-002\":\n",
    "\n",
    "            try:\n",
    "                # load index from disk\n",
    "                print(\">> Loading index from local\")\n",
    "                vector_store = FaissVectorStore.from_persist_dir(\n",
    "                    \"./resources/storage_openai\"\n",
    "                )\n",
    "                storage_context = StorageContext.from_defaults(\n",
    "                    vector_store=vector_store, persist_dir=\"./resources/storage_openai\"\n",
    "                )\n",
    "                index = load_index_from_storage(storage_context=storage_context)\n",
    "                print(\"Index loaded\")\n",
    "\n",
    "            except:\n",
    "                # dimensions of text-ada-embedding-002\n",
    "                print(\">> Loading index from local failed. Recomputing index...\")\n",
    "                dim = 1536\n",
    "                faiss_index = faiss.IndexFlatL2(dim)\n",
    "\n",
    "                vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "                storage_context = StorageContext.from_defaults(\n",
    "                    vector_store=vector_store\n",
    "                )\n",
    "                index = VectorStoreIndex.from_documents(\n",
    "                    documents, storage_context=storage_context\n",
    "                )\n",
    "                index.storage_context.persist(\"./resources/storage_openai\")\n",
    "                print(\"Index loaded\")\n",
    "\n",
    "        elif emb_model.model_name == \"BAAI/bge-large-en-v1.5\":\n",
    "            try:\n",
    "                # load index from disk\n",
    "                print(\">> Loading index from local\")\n",
    "                vector_store = FaissVectorStore.from_persist_dir(\n",
    "                    \"./resources/storage_oss\"\n",
    "                )\n",
    "                storage_context = StorageContext.from_defaults(\n",
    "                    vector_store=vector_store, persist_dir=\"./resources/storage_oss\"\n",
    "                )\n",
    "                index = load_index_from_storage(storage_context=storage_context)\n",
    "                print(\"Index loaded\")\n",
    "            except:\n",
    "                print(\">> Loading index from local failed. Recomputing index...\")\n",
    "                dim = 1024\n",
    "                faiss_index = faiss.IndexFlatL2(dim)\n",
    "                vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "                storage_context = StorageContext.from_defaults(\n",
    "                    vector_store=vector_store\n",
    "                )\n",
    "                index = VectorStoreIndex.from_documents(\n",
    "                    documents, storage_context=storage_context\n",
    "                )\n",
    "                index.storage_context.persist(\"./resources/storage_oss\")\n",
    "                print(\"Index loaded\")\n",
    "\n",
    "        elif emb_model.model_name == \"FinLang/finance-embeddings-investopedia\":\n",
    "            try:\n",
    "                # load index from disk\n",
    "                print(\">> Loading index from local\")\n",
    "                vector_store = FaissVectorStore.from_persist_dir(\n",
    "                    \"./resources/storage_fin_oss\"\n",
    "                )\n",
    "                storage_context = StorageContext.from_defaults(\n",
    "                    vector_store=vector_store, persist_dir=\"./resources/storage_fin_oss\"\n",
    "                )\n",
    "                index = load_index_from_storage(storage_context=storage_context)\n",
    "                print(\"Index loaded\")\n",
    "            except:\n",
    "                print(\">> Loading index from local failed. Recomputing index...\")\n",
    "                dim = 768\n",
    "                faiss_index = faiss.IndexFlatL2(dim)\n",
    "                vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "                storage_context = StorageContext.from_defaults(\n",
    "                    vector_store=vector_store\n",
    "                )\n",
    "                index = VectorStoreIndex.from_documents(\n",
    "                    documents, storage_context=storage_context\n",
    "                )\n",
    "                print(\"Saving index\")\n",
    "                index.storage_context.persist(\"./resources/storage_fin_oss\")\n",
    "                print(\"Index loaded\")\n",
    "\n",
    "        else:\n",
    "            print(\"> Index not loading. Please check\")\n",
    "            break\n",
    "\n",
    "        # configure retriever\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=index,\n",
    "            similarity_top_k=8,\n",
    "        )\n",
    "\n",
    "        # configure response synthesizer\n",
    "        response_synthesizer = get_response_synthesizer(\n",
    "            summary_template=qa_prompt,\n",
    "            response_mode=\"tree_summarize\",\n",
    "        )\n",
    "\n",
    "        # assemble query engine\n",
    "        query_engine = RetrieverQueryEngine(\n",
    "            retriever=retriever,\n",
    "            response_synthesizer=response_synthesizer,\n",
    "        )\n",
    "\n",
    "        # Initialize provider class\n",
    "        from trulens_eval.feedback.provider import OpenAI as LLMJudge\n",
    "\n",
    "        provider = LLMJudge(model_engine=\"gpt-4o\")\n",
    "\n",
    "        # select context to be used in feedback. the location of context is app specific.\n",
    "        context = App.select_context(query_engine)\n",
    "\n",
    "        # Groundtruth SME data\n",
    "        golden_set = test_data.rename(\n",
    "            columns={\"Questions\": \"query\", \"Answers\": \"response\"}\n",
    "        )[[\"query\", \"response\"]].to_dict(orient=\"records\")\n",
    "\n",
    "        # On Actual Groundtruth data\n",
    "        f_groundtruth = Feedback(\n",
    "            GroundTruthAgreement(golden_set).agreement_measure, name=\"Ground Truth\"\n",
    "        ).on_input_output()\n",
    "\n",
    "        # Define a groundedness feedback function\n",
    "        f_groundedness = (\n",
    "            Feedback(\n",
    "                provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "            )\n",
    "            .on(context.collect())  # collect context chunks into a list\n",
    "            .on_output()\n",
    "        )\n",
    "\n",
    "        # Question/answer relevance between overall question and answer.\n",
    "        f_answer_relevance = Feedback(\n",
    "            provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    "        ).on_input_output()\n",
    "        # Question/statement relevance between question and each context chunk.\n",
    "        f_context_relevance = (\n",
    "            Feedback(\n",
    "                provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "            )\n",
    "            .on_input()\n",
    "            .on(context)\n",
    "            .aggregate(np.mean)\n",
    "        )\n",
    "\n",
    "        tru_recorder = TruLlama(\n",
    "            query_engine,\n",
    "            app_id=exp_name,\n",
    "            feedbacks=[f_groundtruth, f_groundedness, f_context_relevance],\n",
    "        )\n",
    "        # with tru_recorder as recording:\n",
    "        #     print(query_engine.query(\"What was the value of Alphabet's total current assets as of December 31, 2023?\"))\n",
    "        # print(\"\\n\")\n",
    "        with tru_recorder as recording:\n",
    "            rag_answers = []\n",
    "            for idx, row in tqdm(\n",
    "                alphabet_10k_question_df.iterrows(),\n",
    "                total=alphabet_10k_question_df.shape[0],\n",
    "            ):\n",
    "                question = row.Questions\n",
    "                response = query_engine.query(question)\n",
    "                try:\n",
    "                    rag_answers.append(\n",
    "                        [\n",
    "                            question,\n",
    "                            [response.response],\n",
    "                            [[x.text] for x in response.source_nodes],\n",
    "                        ]\n",
    "                    )\n",
    "                except:\n",
    "                    rag_answers.append([question, [\"NA\"], []])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\">> Failed for {exp_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e32f3-2a26-4426-957a-a51782e4a962",
   "metadata": {},
   "source": [
    "## Leaderboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2917ed96-3dc6-49a4-b459-a08e71a238b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Exp#3: Llama 3.1 + ada002</th>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>19.466667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp#2 GPT-4o-mini + ada002</th>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>19.466667</td>\n",
       "      <td>0.000764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp#5: Llama 3.1 + bge-large</th>\n",
       "      <td>0.279583</td>\n",
       "      <td>0.596667</td>\n",
       "      <td>0.555172</td>\n",
       "      <td>19.466667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Context Relevance  Groundedness  Ground Truth  \\\n",
       "app_id                                                                        \n",
       "Exp#3: Llama 3.1 + ada002              0.344167      0.633333      0.676667   \n",
       "Exp#2 GPT-4o-mini + ada002             0.343750      0.966667      0.900000   \n",
       "Exp#5: Llama 3.1 + bge-large           0.279583      0.596667      0.555172   \n",
       "\n",
       "                                latency  total_cost  \n",
       "app_id                                               \n",
       "Exp#3: Llama 3.1 + ada002     19.466667    0.000000  \n",
       "Exp#2 GPT-4o-mini + ada002    19.466667    0.000764  \n",
       "Exp#5: Llama 3.1 + bge-large  19.466667    0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e6f6c-a76e-45cc-9fb9-653afd215c21",
   "metadata": {},
   "source": [
    "## Dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e136682f-0792-4759-9a99-cdeeb0f0d59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path:   Network URL: http://192.168.1.2:60486\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1dc1b-07e8-495f-9cb9-7baf23af17b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
